{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection and Performance Testing<br>\n",
    "Results from the model_selection_v0 python notebook got me here, which is testing some optimized Logistic Regression models for use in predicting risk of 7 day mortality. In this notebook, I'll be finalizing the models and reporting on performance of the trained models on validation data, using 10-fold cross validation. <br><br>\n",
    "\n",
    "Additionally, other models will be ran (kNN, decision tree, maybe neural net) to show other future options, show a performance ceiling given the data inputs, despite the lack of model interpretability. I think a long-term modeling option is deep learning methods, or even XGboost, but right now, the models need to be fully interpretable. Thus, the focus on logistic regression.<br><br>\n",
    "\n",
    "While the previous notebook identified median columnar imputation of missing data as the superior method (when compared to adding 0 for missing data), I'm still going to test each model version against both methods of imputation, as I think it would be worthwhile to quantify the improvements in model performance with median imputation. Additionally, seeing errors for each imputation method will be informative. <br><br>\n",
    "\n",
    "One data processing step I would like to also test is z-scaling (normalizing data to mean = 0, sd = 1) for all data. By doing this, I think I will get a better representation of which variables appear to be most informative of the outcome, which again will help with interpretability clinically. While yes, the scales themselves will need to be re-converted for direct interpretation, I don't think this will be necessary, as most people right now just want to know WHAT is informative, not necessarily how much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "from IPython.display import display #displays full dataframe columns\n",
    "#display all dataframe columns when printed\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df = pd.read_csv('C:/Users/Mark.Burghart/Documents/projects/hospice_carepoint/data/transformed/carepoint_transformed_dummied.csv', index_col=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split<br>\n",
    "Same split and randomizer will be used from the previous model_selection_v0 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate variables (X) from outcome of interest (y)\n",
    "df.shape\n",
    "cols = df.columns.get_values() #converts column names to list\n",
    "cols = cols.tolist()\n",
    "feature_cols = [x for x in cols if x != 'death_within_7_days'] #removes outcome of interest from list ('death_within_7_days')\n",
    "\n",
    "#extract rows\n",
    "#print(feature_cols) #debug\n",
    "X = df.loc[:, feature_cols]\n",
    "X.shape #outcome column has been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save outcome variable as y\n",
    "y = df.death_within_7_days\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate data into training/test (aka holdout) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 23) #random_state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create objects with specific imputation method\n",
    "#impute missing values: replacing NaNs with Median Column value for each column\n",
    "X_train_med = X_train.fillna(X_train.median()) \n",
    "y_train_med = y_train.fillna(y_train.median())\n",
    "\n",
    "#impute missing values: replacing NaNs with 0\n",
    "X_train_zero = X_train.fillna(0)\n",
    "y_train_zero = y_train.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training<br>\n",
    "\n",
    "Below, I have created a python sklearn pipeline to implement a series of steps before acquiring outputs. First, the data is standardized to a mean of 0 and a SD of 1 (aka. Z-scaling, standard scaling). Next, the top 40 features are selected based on F-test of ANOVA procedure. Finally, a logistic regression (L1 or L2) is built with specified C parameter obtained from v0 model selection notebook. Lastly, the scores for each cross validation fold are printed, along with the collective cross validation mean from the 10 folds. <br><br>\n",
    "#### L1 LASSO Logistic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#pipeline for cross validation, preprocessing, feature selection, and model training of L1 Logistic Regression\n",
    "L1_pipeline = make_pipeline(StandardScaler(), SelectKBest(f_classif, k = 40), LogisticRegression(penalty = 'l1', random_state = 0, C = 100))\n",
    "#L1 median imputation data\n",
    "scores_L1_med = cross_val_score(L1_pipeline, X_train_med, y_train_med, cv = 10, scoring = 'roc_auc')\n",
    "print(\"Cross validation AUC scores from each 10-fold run for L1 Regression (Median impute): \")\n",
    "scores_L1_med\n",
    "print(\"Mean cross validation AUC from 10-fold CV for L1 Regression (Median impute): \")\n",
    "scores_L1_med.mean()\n",
    "#L1 zero imputation data\n",
    "scores_L1_zero = cross_val_score(L1_pipeline, X_train_zero, y_train_zero, cv = 10, scoring = 'roc_auc')\n",
    "print(\"Cross validation AUC scores from each 10-fold run for L1 Regression (Zero impute): \")\n",
    "scores_L1_zero\n",
    "print(\"Mean cross validation AUC from 10-fold CV for L1 Regression (Zero impute): \")\n",
    "scores_L1_zero.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 Ridge Penalty Logistic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#pipeline for CV, feature selection, model training of L2 Logistic Regression\n",
    "L2_pipeline = make_pipeline(StandardScaler(), SelectKBest(f_classif, k = 40), LogisticRegression(penalty = 'l2', random_state = 0, C = 10))\n",
    "#L2 median imputation data\n",
    "scores_L2_med = cross_val_score(L2_pipeline, X_train_med, y_train_med, cv = 10, scoring = 'roc_auc')\n",
    "print(\"Cross validation AUC scores from each 10-fold run for L2 Regression (Median impute): \")\n",
    "scores_L2_med\n",
    "print(\"Mean cross validation AUC from 10-fold CV for L2 Regression (Median impute): \")\n",
    "scores_L2_med.mean()\n",
    "#L2 zero imputation data\n",
    "scores_L2_zero = cross_val_score(L2_pipeline, X_train_med, y_train_med, cv = 10, scoring = 'roc_auc')\n",
    "print(\"Cross validation AUC scores from each 10-fold run for L2 Regression (Zero impute): \")\n",
    "scores_L2_zero\n",
    "print(\"Mean cross validation AUC from 10-fold CV for L2 Regression (Zero impute): \")\n",
    "scores_L2_zero.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
