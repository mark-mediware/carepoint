{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier #baseline model\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "from IPython.display import display #displays full dataframe columns\n",
    "#display all dataframe columns when printed\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271541, 120)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "df = pd.read_csv('C:/Users/Mark.Burghart/Documents/projects/hospice_carepoint/data/transformed/carepoint_transformed_dummied.csv', index_col=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to still create building/holdout sets (80/20), cross validation of building set, impute missing values (set to 0 for now).\n",
    "<br>\n",
    "<br>\n",
    "Pipeline todo: missing data, feature selection, grid search hyperparameter tuning, model training.\n",
    "<br><br>\n",
    "pipe flow: Fill in missing data, feature selection, model training and tuning via grid search. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271541, 119)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separate variables (X) from outcome of interest (y)\n",
    "df.shape\n",
    "cols = df.columns.get_values() #converts column names to list\n",
    "cols = cols.tolist()\n",
    "feature_cols = [x for x in cols if x != 'death_within_7_days'] #removes outcome of interest from list ('death_within_7_days')\n",
    "\n",
    "#extract rows\n",
    "#print(feature_cols) #debug\n",
    "X = df.loc[:, feature_cols]\n",
    "X.shape #outcome column has been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271541,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save outcome variable as y\n",
    "y = df.death_within_7_days\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate data into training/test (aka holdout) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 23) #random_state for reproducibility (if needed)\n",
    "#X_test, y_test should not be used until NO MORE decisions are being made. This is the final, FINAL validation, and more often just used for model performance and generalizability!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "# Pipepline for imputation, feature selection, and model training/tuning<br><br>\n",
    "#### Logistic Regression with L1 Lasso Penalty, imputation = Median columnar value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First up: Logistic Regression models. Going to try both L1 and L2 Regularization.<br><br>\n",
    "Note: For *MISSING DATA*,  I am **IMPUTING THE MEDIAN COLUMN VALUE**, as opposed to setting to 0, or kNN imputation as of now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest = SelectKBest(f_classif) #select best 'k' features\n",
    "logreg = LogisticRegression(penalty = 'l1', random_state = 0) #L1 Regularization\n",
    "impute = Imputer(missing_values = 'NaN', strategy = 'median', axis = 0) #impute missing values: replacing NaNs with Median Column value for each column\n",
    "\n",
    "#Pipeline for Logistic Regression with L1 Lasso Regularization\n",
    "pipe_lr_l1 = Pipeline([('imputer', impute),\n",
    "                       ('kbest', kbest),\n",
    "                      ('lr', logreg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for grid search cross validation \n",
    "parameters = {'kbest__k': [5, 10, 20,40, 60], #building models with 40, 60, 80, and 100 most significant variables\n",
    "                 'lr__C' : [0.01, 0.1, 1, 10, 100]} #tuning C for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search\n",
    "grid = GridSearchCV(pipe_lr_l1, parameters, cv = 5, scoring = 'roc_auc') #run grid on parameters, 5-fold cross validation, AUC is evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)), ('kbest', SelectKBest(k=10, score_func=<function f_classif at 0x000001D758DF30D0>)), ('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'kbest__k': [5, 10, 20, 40, 60], 'lr__C': [0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#fit models\n",
    "grid.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model interpretations:<br><br>\n",
    "feature [86] is constant, meaning the value is constant for all visits and patients (and should be removed from model).<br><br>\n",
    "true_divide warning is likely due to feature[86], and is trying to divide by 0 variance...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "Pipeline(memory=None,\n",
      "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)), ('kbest', SelectKBest(k=60, score_func=<function f_classif at 0x000001D758DF30D0>)), ('lr', LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Logistic Regression step:\n",
      "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Logistic Regression coefficients:\n",
      "[[ 9.52683832e-04 -1.32666922e-01  1.19567914e-01  1.69686820e-01\n",
      "  -1.01592255e-02  9.30324824e-02  5.69836653e-02  9.69037316e-02\n",
      "  -4.59095858e-03  4.14169229e-02  1.53879735e-01  1.20989111e-01\n",
      "   1.07812544e-01  1.79547202e-01 -2.17536858e-02 -5.33387353e-02\n",
      "  -1.19502729e-02  4.84072800e-02  3.10457016e-02  4.65516862e-02\n",
      "   5.24860120e-02 -9.38383917e-02  6.43849016e-02 -3.27581190e-02\n",
      "  -1.47932913e-01 -6.28983605e-02 -9.05382957e-02 -2.22725596e-01\n",
      "   5.23189960e-02  7.46039815e-02  3.17239046e-02 -7.00114841e-02\n",
      "  -3.51952582e-02 -7.19563605e-02 -9.15547865e-02  7.57175911e-02\n",
      "  -9.77185174e-02 -4.15050614e-02 -4.83598814e-02 -1.63318886e-02\n",
      "  -1.19760171e-02 -2.42172796e-02 -1.48213854e-02 -3.07466560e-02\n",
      "   1.04659761e-02  2.95015449e-02 -9.26388478e-03  1.09772835e-02\n",
      "  -3.89540036e-01  2.08573298e-02  1.55618035e-02  3.26809137e-01\n",
      "   4.57919480e-01  1.44271967e+00 -8.39588277e-02  4.79936463e-01\n",
      "   2.80831084e-02  5.01410403e-01 -9.13027207e-02  2.62500613e-01]]\n",
      "Best Parameters: {'kbest__k': 60, 'lr__C': 100}\n",
      "Best cross validation score: 0.81\n"
     ]
    }
   ],
   "source": [
    "print(\"Best estimator:\\n{}\".format(grid.best_estimator_)) #prints best model and pipeline\n",
    "print(\"Logistic Regression step:\\n{}\".format(grid.best_estimator_.named_steps[\"lr\"])) #prints logistic regression step of pipeline\n",
    "print(\"Logistic Regression coefficients:\\n{}\".format(grid.best_estimator_.named_steps[\"lr\"].coef_)) #prints coefficients of best estimator\n",
    "print(\"Best Parameters: {}\".format(grid.best_params_)) #outputs best parameters settings\n",
    "print(\"Best cross validation score: {:.2f}\".format(grid.best_score_)) #best produced cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid scores on training set: \n",
      "0.753 (+/-0.001) for {'kbest__k': 5, 'lr__C': 0.01}\n",
      "0.753 (+/-0.001) for {'kbest__k': 5, 'lr__C': 0.1}\n",
      "0.753 (+/-0.001) for {'kbest__k': 5, 'lr__C': 1}\n",
      "0.753 (+/-0.001) for {'kbest__k': 5, 'lr__C': 10}\n",
      "0.753 (+/-0.001) for {'kbest__k': 5, 'lr__C': 100}\n",
      "0.766 (+/-0.001) for {'kbest__k': 10, 'lr__C': 0.01}\n",
      "0.766 (+/-0.001) for {'kbest__k': 10, 'lr__C': 0.1}\n",
      "0.766 (+/-0.001) for {'kbest__k': 10, 'lr__C': 1}\n",
      "0.766 (+/-0.001) for {'kbest__k': 10, 'lr__C': 10}\n",
      "0.766 (+/-0.001) for {'kbest__k': 10, 'lr__C': 100}\n",
      "0.787 (+/-0.001) for {'kbest__k': 20, 'lr__C': 0.01}\n",
      "0.787 (+/-0.001) for {'kbest__k': 20, 'lr__C': 0.1}\n",
      "0.787 (+/-0.001) for {'kbest__k': 20, 'lr__C': 1}\n",
      "0.787 (+/-0.001) for {'kbest__k': 20, 'lr__C': 10}\n",
      "0.787 (+/-0.001) for {'kbest__k': 20, 'lr__C': 100}\n",
      "0.807 (+/-0.000) for {'kbest__k': 40, 'lr__C': 0.01}\n",
      "0.808 (+/-0.000) for {'kbest__k': 40, 'lr__C': 0.1}\n",
      "0.808 (+/-0.000) for {'kbest__k': 40, 'lr__C': 1}\n",
      "0.808 (+/-0.000) for {'kbest__k': 40, 'lr__C': 10}\n",
      "0.808 (+/-0.000) for {'kbest__k': 40, 'lr__C': 100}\n",
      "0.813 (+/-0.001) for {'kbest__k': 60, 'lr__C': 0.01}\n",
      "0.814 (+/-0.000) for {'kbest__k': 60, 'lr__C': 0.1}\n",
      "0.814 (+/-0.000) for {'kbest__k': 60, 'lr__C': 1}\n",
      "0.814 (+/-0.000) for {'kbest__k': 60, 'lr__C': 10}\n",
      "0.814 (+/-0.000) for {'kbest__k': 60, 'lr__C': 100}\n",
      "Grid scores on Development set: \n",
      "0.753 (+/-0.003) for {'kbest__k': 5, 'lr__C': 0.01}\n",
      "0.753 (+/-0.003) for {'kbest__k': 5, 'lr__C': 0.1}\n",
      "0.753 (+/-0.003) for {'kbest__k': 5, 'lr__C': 1}\n",
      "0.753 (+/-0.003) for {'kbest__k': 5, 'lr__C': 10}\n",
      "0.753 (+/-0.003) for {'kbest__k': 5, 'lr__C': 100}\n",
      "0.765 (+/-0.002) for {'kbest__k': 10, 'lr__C': 0.01}\n",
      "0.766 (+/-0.003) for {'kbest__k': 10, 'lr__C': 0.1}\n",
      "0.766 (+/-0.003) for {'kbest__k': 10, 'lr__C': 1}\n",
      "0.766 (+/-0.003) for {'kbest__k': 10, 'lr__C': 10}\n",
      "0.766 (+/-0.003) for {'kbest__k': 10, 'lr__C': 100}\n",
      "0.787 (+/-0.002) for {'kbest__k': 20, 'lr__C': 0.01}\n",
      "0.787 (+/-0.002) for {'kbest__k': 20, 'lr__C': 0.1}\n",
      "0.787 (+/-0.002) for {'kbest__k': 20, 'lr__C': 1}\n",
      "0.787 (+/-0.002) for {'kbest__k': 20, 'lr__C': 10}\n",
      "0.787 (+/-0.002) for {'kbest__k': 20, 'lr__C': 100}\n",
      "0.807 (+/-0.002) for {'kbest__k': 40, 'lr__C': 0.01}\n",
      "0.807 (+/-0.002) for {'kbest__k': 40, 'lr__C': 0.1}\n",
      "0.807 (+/-0.002) for {'kbest__k': 40, 'lr__C': 1}\n",
      "0.807 (+/-0.002) for {'kbest__k': 40, 'lr__C': 10}\n",
      "0.807 (+/-0.002) for {'kbest__k': 40, 'lr__C': 100}\n",
      "0.813 (+/-0.002) for {'kbest__k': 60, 'lr__C': 0.01}\n",
      "0.814 (+/-0.002) for {'kbest__k': 60, 'lr__C': 0.1}\n",
      "0.814 (+/-0.002) for {'kbest__k': 60, 'lr__C': 1}\n",
      "0.814 (+/-0.002) for {'kbest__k': 60, 'lr__C': 10}\n",
      "0.814 (+/-0.002) for {'kbest__k': 60, 'lr__C': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#AUC scores for each training set run\n",
    "print(\"Grid scores on training set: \")\n",
    "means = grid.cv_results_['mean_train_score']\n",
    "stds = grid.cv_results_['std_train_score']\n",
    "\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']): #note imbedded grid_l2 will need to be adjusted to correct object\n",
    "    print(\"%0.3f (+/-%0.3f) for %r\"\n",
    "         % (mean, std *2, params))\n",
    "    \n",
    "#AUC scores for each validation set run\n",
    "print(\"Grid scores on Development set: \")\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']): #note imbedded grid_l2 will need to be adjusted to correct object\n",
    "    print(\"%0.3f (+/-%0.3f) for %r\"\n",
    "         % (mean, std *2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return variables of significance\n",
    "#start with 40\n",
    "fill_NaN = Imputer(missing_values=np.nan, strategy='median', axis=0)\n",
    "imputed_X_train = pd.DataFrame(fill_NaN.fit_transform(X_train))\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_train.index = X_train.index\n",
    "\n",
    "#display columns..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gender', 'Anxiety', 'Depression', 'Drowsiness', 'Lack_of_Appetite',\n",
      "       'Nausea', 'Pain', 'Shortness_of_Breath', 'Tiredness', 'Wellbeing',\n",
      "       'LengthOfCare_days', '3_visit_max_anxiety', '3_visit_max_depression',\n",
      "       '3_visit_max_drowsiness', '3_visit_max_lackofappetite',\n",
      "       '3_visit_max_nausea', '3_visit_max_pain',\n",
      "       '3_visit_max_shortnessofbreath', '3_visit_max_tiredness',\n",
      "       '3_visit_max_wellbeing', '5_visit_max_anxiety',\n",
      "       '5_visit_max_depression', '5_visit_max_drowsiness',\n",
      "       '5_visit_max_lackofappetite', '5_visit_max_nausea', '5_visit_max_pain',\n",
      "       '5_visit_max_shortnessofbreath', '5_visit_max_tiredness',\n",
      "       '5_visit_max_wellbeing', '3_visit_mean_anxiety',\n",
      "       '3_visit_mean_depression', '3_visit_mean_drowsiness',\n",
      "       '3_visit_mean_lackofappetite', '3_visit_mean_nausea',\n",
      "       '3_visit_mean_pain', '3_visit_mean_shortnessofbreath',\n",
      "       '3_visit_mean_tiredness', '3_visit_mean_wellbeing',\n",
      "       '5_visit_mean_depression', '5_visit_mean_drowsiness',\n",
      "       '5_visit_mean_lackofappetite', '5_visit_mean_pain',\n",
      "       '5_visit_mean_shortnessofbreath', '5_visit_mean_tiredness',\n",
      "       '5_visit_mean_wellbeing', 'Anxiety_change', 'Depression_change',\n",
      "       'Drowsiness_change', 'LackofAppetite_change', 'Nausea_change',\n",
      "       'ShortnessofBreath_change', 'Tiredness_change', 'Wellbeing_change',\n",
      "       'Age', 'ESAS_visit_total', '3_visit_max_esas', '5_visit_max_esas',\n",
      "       '3_visit_mean_esas', '5_visit_mean_esas', 'ESAS_change',\n",
      "       'AdvanceDirective_Yes - Do Not Resuscitate (DNR)',\n",
      "       'AdvanceDirective_Yes - Full Code / Advanced Cardiac Life Support (ACLS)',\n",
      "       'ReferralType_Clinic or physician's office',\n",
      "       'ReferralType_Court/Law Enforcement',\n",
      "       'ReferralType_Information not available',\n",
      "       'ReferralType_Non-health care facility',\n",
      "       'ReferralType_Transfer from Home Health Agency',\n",
      "       'ReferralType_Transfer from Hospice',\n",
      "       'ReferralType_Transfer from SNF or ICF',\n",
      "       'ReferralType_Transfer from hospital', 'LevelofCare_Continuous (CHC)',\n",
      "       'LevelofCare_Inpatient (GIP)', 'LevelofCare_Routine',\n",
      "       'Race_American Indian or Alaskan Native', 'Race_Asian',\n",
      "       'Race_Black or African American', 'Race_Hispanic or Latino',\n",
      "       'Race_Native Hawaiian or Pacific Islander', 'Race_White',\n",
      "       'InsuranceType_Medicaid (HMO/Managed Care)',\n",
      "       'InsuranceType_Medicare Traditional', 'InsuranceType_Other',\n",
      "       'InsuranceType_Other Government',\n",
      "       'InsuranceType_Private HMO/Managed Care',\n",
      "       'InsuranceType_Private Insurance', 'InsuranceType_Private Pay',\n",
      "       'InsuranceType_Self-Pay',\n",
      "       'icd10_cluster_Certain conditions originating in the perinatal period',\n",
      "       'icd10_cluster_Certain infectious and parasitic diseases',\n",
      "       'icd10_cluster_Congenital malformations, deformations and chromosomal abnormalities',\n",
      "       'icd10_cluster_Diseases of the circulatory system',\n",
      "       'icd10_cluster_Diseases of the digestive system',\n",
      "       'icd10_cluster_Diseases of the genitourinary system',\n",
      "       'icd10_cluster_Diseases of the nervous system',\n",
      "       'icd10_cluster_Diseases of the respiratory system',\n",
      "       'icd10_cluster_Diseases of the skin and subcutaneous tissue',\n",
      "       'icd10_cluster_Endocrine, nutritional, and metabolic diseases',\n",
      "       'icd10_cluster_Injury, poisonining, and certain other consequences of external causes',\n",
      "       'icd10_cluster_Mental and behavioural disorders',\n",
      "       'icd10_cluster_Neoplasms'],\n",
      "      dtype='object')\n",
      "[1.39639765e+02 5.53526305e+02 2.26788422e+02 2.01742152e+04\n",
      " 2.72523017e+04 7.59494229e+01 9.72511216e+02 4.39515476e+03\n",
      " 1.90306416e+04 9.63413484e+03 4.91992871e+03 1.06550276e+03\n",
      " 3.61965269e+00 1.59568080e+04 1.91791931e+04 4.62453430e+01\n",
      " 2.21227066e+03 3.47081652e+03 1.41164880e+04 6.20866855e+03\n",
      " 4.33358136e+02 1.75625477e+01 9.73190319e+03 1.18132839e+04\n",
      " 3.90799786e+00 1.38156565e+03 1.79441042e+03 8.26320409e+03\n",
      " 3.59809945e+03 6.48067848e+01 3.48774803e+02 1.09940378e+04\n",
      " 1.63347417e+04 1.86669215e+01 5.03239221e+02 9.91341917e+02\n",
      " 1.23513887e+04 6.06793656e+03 2.12169711e+00 4.14300049e+02\n",
      " 6.06018694e+03 9.98998475e+03 4.42916930e-03 1.85285625e+02\n",
      " 2.44242586e+02 7.71492995e+03 3.43520195e+03 9.80567789e+00\n",
      " 6.85092525e+00 1.10275455e+03 1.16543256e+03 5.25006095e+00\n",
      " 2.02896973e+00 7.59932101e+02 8.20228337e+02 4.29440419e+02\n",
      " 1.92851110e+01 7.97722679e+03 4.36305815e+03 2.51169854e+03\n",
      " 3.45220034e+03 1.68414118e+03 4.46570174e+02 2.90981603e+00\n",
      " 1.59852397e+00 5.94693920e+01 4.78266673e+02 3.11369165e+02\n",
      " 1.27956769e+01 4.07761378e+01 4.39045540e+02 1.76352275e+02\n",
      " 1.13142359e+02 2.18056354e+01 3.04911190e+03 2.36509985e+02\n",
      " 8.36734446e+03 3.22009039e+00 6.11453484e+03 8.24524524e+00\n",
      " 1.03100386e+01 5.78477024e+01 5.66931788e+01 2.13696264e+01\n",
      " 1.30153506e+02 1.18519167e+01 3.12628784e-01 2.64716683e+00\n",
      " 6.23603098e-01 8.72748984e-02 4.31799374e+01 2.54120026e-02\n",
      " 1.63499256e+01 1.37349156e+01 1.50365065e+02 3.57169898e+01\n",
      " 6.33253435e+00 2.02023973e+01 1.16778903e+00 1.06985550e+00\n",
      " 3.12648215e+00 2.82066846e+00 6.39755578e+00 2.08746621e+02\n",
      " 1.35073853e+01 2.69275441e+00 1.89320130e+02 1.51079912e+01\n",
      " 3.03940909e+02 1.82027164e+00 5.09223710e+02 9.24890696e+01\n",
      " 2.15739260e+01 2.61549903e+01 2.70912523e+00 8.95320646e+01\n",
      " 3.80683045e+00 1.16502978e+03 2.45941179e+00]\n"
     ]
    }
   ],
   "source": [
    "#return variables of significance\n",
    "#Return 100 features used in best model\n",
    "selector = SelectKBest(f_classif, k = 100)\n",
    "selector.fit(imputed_X_train, y_train)\n",
    "features = imputed_X_train.columns[selector.get_support()]\n",
    "print(features)\n",
    "scores = selector.scores_ #saves scores of features\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression with L1 penalty and median missing data imputation** <br><br>\n",
    "- Best model selected used parameters K = 100 (100 variables included), and C = 1 for LogReg model. \n",
    "- AUC scores ranged from 0.807 (40 variables, C = 0.01-100) to 0.817"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with L2 Ridge Penalty, imputation = Median columnar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression with L2 Regularization penalty\n",
    "kbest = SelectKBest(f_classif) #select best 'k' features\n",
    "logreg_l2 = LogisticRegression(penalty = 'l2', random_state = 0) #L2 Ridge Regularization\n",
    "impute = Imputer(missing_values = 'NaN', strategy = 'median', axis = 0) #impute missing values: replacing NaNs with Median Column value for each column\n",
    "\n",
    "#Pipeline for Logistic Regression with L2 'Ridge' Regularization\n",
    "pipe_lr_l2 = Pipeline([('imputer', impute),\n",
    "                       ('kbest', kbest),\n",
    "                      ('lr', logreg_l2)])\n",
    "#parameters for grid search cross validation \n",
    "parameters = {'kbest__k': [5, 10, 20, 40, 60], #building models with 40, 60, 80, and 100 most significant variables\n",
    "                 'lr__C' : [0.01, 0.1, 1, 10, 100]} #tuning C for logistic regression\n",
    "\n",
    "#grid search\n",
    "grid_l2 = GridSearchCV(pipe_lr_l2, parameters, cv = 5, scoring = 'roc_auc') #run grid on parameters, 5-fold cross validation, AUC is evaluation metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)), ('kbest', SelectKBest(k=10, score_func=<function f_classif at 0x000001D758DF30D0>)), ('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'kbest__k': [5, 10, 20, 40, 60], 'lr__C': [0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#fit models\n",
    "grid_l2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "Pipeline(memory=None,\n",
      "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)), ('kbest', SelectKBest(k=60, score_func=<function f_classif at 0x000001D758DF30D0>)), ('lr', LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Logistic Regression step:\n",
      "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Logistic Regression coefficients:\n",
      "[[ 8.48669711e-04 -1.32466987e-01  1.19507325e-01  1.69695960e-01\n",
      "  -1.00971379e-02  9.30824113e-02  5.72070777e-02  9.71376716e-02\n",
      "  -4.58782396e-03  4.17210402e-02  1.53928058e-01  1.21826118e-01\n",
      "   1.08384728e-01  1.80426797e-01 -1.99880085e-02 -5.09853438e-02\n",
      "  -1.21642673e-02  4.82039093e-02  3.03597460e-02  4.60698330e-02\n",
      "   5.18031480e-02 -9.51375456e-02  6.23712201e-02 -3.36755036e-02\n",
      "  -1.47993345e-01 -6.39781338e-02 -9.15826694e-02 -2.24037525e-01\n",
      "   5.00185114e-02  7.14070015e-02  3.27160733e-02 -6.95660974e-02\n",
      "  -3.41448126e-02 -7.09312795e-02 -9.03962599e-02  7.73641760e-02\n",
      "  -9.49993332e-02 -4.14485331e-02 -4.83589586e-02 -1.63601174e-02\n",
      "  -1.21164429e-02 -2.43558984e-02 -1.49284195e-02 -3.26519862e-02\n",
      "   1.21043462e-02  3.19636408e-02 -1.15237265e-02  1.10542448e-02\n",
      "  -3.89076009e-01  2.08749417e-02  1.53772854e-02  3.26624179e-01\n",
      "   4.49645684e-01  1.43409840e+00 -9.15976060e-02  4.79915734e-01\n",
      "   2.78634769e-02  4.99456638e-01 -9.15865753e-02  2.62242617e-01]]\n",
      "Best Parameters: {'kbest__k': 60, 'lr__C': 10}\n",
      "Best cross validation score: 0.81\n"
     ]
    }
   ],
   "source": [
    "print(\"Best estimator:\\n{}\".format(grid_l2.best_estimator_)) #prints best model and pipeline\n",
    "print(\"Logistic Regression step:\\n{}\".format(grid_l2.best_estimator_.named_steps[\"lr\"])) #prints logistic regression step of pipeline\n",
    "print(\"Logistic Regression coefficients:\\n{}\".format(grid_l2.best_estimator_.named_steps[\"lr\"].coef_)) #prints coefficients of best estimator\n",
    "print(\"Best Parameters: {}\".format(grid_l2.best_params_)) #outputs best parameters settings\n",
    "print(\"Best cross validation score: {:.2f}\".format(grid_l2.best_score_)) #best produced cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid scores on Development set: \n",
      "0.753 (+/-0.001) for {'kbest__k': 5, 'lr__C': 0.01}\n",
      "0.753 (+/-0.001) for {'kbest__k': 5, 'lr__C': 0.1}\n",
      "0.753 (+/-0.001) for {'kbest__k': 5, 'lr__C': 1}\n",
      "0.753 (+/-0.001) for {'kbest__k': 5, 'lr__C': 10}\n",
      "0.753 (+/-0.001) for {'kbest__k': 5, 'lr__C': 100}\n",
      "0.766 (+/-0.001) for {'kbest__k': 10, 'lr__C': 0.01}\n",
      "0.766 (+/-0.001) for {'kbest__k': 10, 'lr__C': 0.1}\n",
      "0.766 (+/-0.001) for {'kbest__k': 10, 'lr__C': 1}\n",
      "0.766 (+/-0.001) for {'kbest__k': 10, 'lr__C': 10}\n",
      "0.766 (+/-0.001) for {'kbest__k': 10, 'lr__C': 100}\n",
      "0.787 (+/-0.001) for {'kbest__k': 20, 'lr__C': 0.01}\n",
      "0.787 (+/-0.001) for {'kbest__k': 20, 'lr__C': 0.1}\n",
      "0.787 (+/-0.001) for {'kbest__k': 20, 'lr__C': 1}\n",
      "0.787 (+/-0.001) for {'kbest__k': 20, 'lr__C': 10}\n",
      "0.787 (+/-0.001) for {'kbest__k': 20, 'lr__C': 100}\n",
      "0.807 (+/-0.000) for {'kbest__k': 40, 'lr__C': 0.01}\n",
      "0.808 (+/-0.000) for {'kbest__k': 40, 'lr__C': 0.1}\n",
      "0.808 (+/-0.000) for {'kbest__k': 40, 'lr__C': 1}\n",
      "0.808 (+/-0.000) for {'kbest__k': 40, 'lr__C': 10}\n",
      "0.808 (+/-0.000) for {'kbest__k': 40, 'lr__C': 100}\n",
      "0.813 (+/-0.001) for {'kbest__k': 60, 'lr__C': 0.01}\n",
      "0.814 (+/-0.000) for {'kbest__k': 60, 'lr__C': 0.1}\n",
      "0.814 (+/-0.000) for {'kbest__k': 60, 'lr__C': 1}\n",
      "0.814 (+/-0.000) for {'kbest__k': 60, 'lr__C': 10}\n",
      "0.814 (+/-0.000) for {'kbest__k': 60, 'lr__C': 100}\n",
      "Grid scores on Development set: \n",
      "0.753 (+/-0.003) for {'kbest__k': 5, 'lr__C': 0.01}\n",
      "0.753 (+/-0.003) for {'kbest__k': 5, 'lr__C': 0.1}\n",
      "0.753 (+/-0.003) for {'kbest__k': 5, 'lr__C': 1}\n",
      "0.753 (+/-0.003) for {'kbest__k': 5, 'lr__C': 10}\n",
      "0.753 (+/-0.003) for {'kbest__k': 5, 'lr__C': 100}\n",
      "0.765 (+/-0.003) for {'kbest__k': 10, 'lr__C': 0.01}\n",
      "0.766 (+/-0.003) for {'kbest__k': 10, 'lr__C': 0.1}\n",
      "0.766 (+/-0.003) for {'kbest__k': 10, 'lr__C': 1}\n",
      "0.766 (+/-0.003) for {'kbest__k': 10, 'lr__C': 10}\n",
      "0.766 (+/-0.003) for {'kbest__k': 10, 'lr__C': 100}\n",
      "0.786 (+/-0.002) for {'kbest__k': 20, 'lr__C': 0.01}\n",
      "0.787 (+/-0.002) for {'kbest__k': 20, 'lr__C': 0.1}\n",
      "0.787 (+/-0.002) for {'kbest__k': 20, 'lr__C': 1}\n",
      "0.787 (+/-0.002) for {'kbest__k': 20, 'lr__C': 10}\n",
      "0.787 (+/-0.002) for {'kbest__k': 20, 'lr__C': 100}\n",
      "0.807 (+/-0.002) for {'kbest__k': 40, 'lr__C': 0.01}\n",
      "0.807 (+/-0.002) for {'kbest__k': 40, 'lr__C': 0.1}\n",
      "0.807 (+/-0.002) for {'kbest__k': 40, 'lr__C': 1}\n",
      "0.807 (+/-0.002) for {'kbest__k': 40, 'lr__C': 10}\n",
      "0.807 (+/-0.002) for {'kbest__k': 40, 'lr__C': 100}\n",
      "0.813 (+/-0.002) for {'kbest__k': 60, 'lr__C': 0.01}\n",
      "0.814 (+/-0.002) for {'kbest__k': 60, 'lr__C': 0.1}\n",
      "0.814 (+/-0.002) for {'kbest__k': 60, 'lr__C': 1}\n",
      "0.814 (+/-0.002) for {'kbest__k': 60, 'lr__C': 10}\n",
      "0.814 (+/-0.002) for {'kbest__k': 60, 'lr__C': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#AUC scores for each training set run\n",
    "print(\"Grid scores on Development set: \")\n",
    "means = grid.cv_results_['mean_train_score']\n",
    "stds = grid.cv_results_['std_train_score']\n",
    "\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']): #note imbedded grid_l2 will need to be adjusted to correct object\n",
    "    print(\"%0.3f (+/-%0.3f) for %r\"\n",
    "         % (mean, std *2, params))\n",
    "\n",
    "#AUC scores for each validation set run\n",
    "print(\"Grid scores on Development set: \")\n",
    "means = grid_l2.cv_results_['mean_test_score']\n",
    "stds = grid_l2.cv_results_['std_test_score']\n",
    "\n",
    "for mean, std, params in zip(means, stds, grid_l2.cv_results_['params']): #note imbedded grid_l2 will need to be adjusted to correct object\n",
    "    print(\"%0.3f (+/-%0.3f) for %r\"\n",
    "         % (mean, std *2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Br>**Logistic Regression with L2 penalty and median missing data imputation**<br><br>\n",
    "- Best model selected used parameters K = 100 (100 variables included), and C = 10 for LogReg model. <br>\n",
    "- AUC scores ranged from 0.807 (40 variables, C = 0.01-100) to 0.817 \n",
    "- Interestingly, these outputs produced the same AUC across all cross validation trials as L1 model.\n",
    "    -Only difference was C = 1 for L1. \n",
    "    - Could be due to same random_state parameter?<br>\n",
    "    <br>\n",
    "    \n",
    "    Also interesting to note that adding 60 additional variables only improves AUC by ~1%. 100 variables is likely overfitting...\n",
    "    <br><Br>\n",
    "    Not sure why the training and test validation scores are exactly the same...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNearest Neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# creating odd list of K for KNN\n",
    "neighbors = [1,3,5,7]\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "# perform 5-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, imputed_X_train, y_train, cv=5, scoring='roc_auc') #using median imputed dataset for training\n",
    "    cv_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d71ab4b9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80191911 0.80626449 0.80662309 0.80448436 0.80376759]\n"
     ]
    }
   ],
   "source": [
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k\n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print(\"The optimal number of neighbors is %d\" % optimal_k)\n",
    "\n",
    "# plot misclassification error vs k\n",
    "plt.plot(neighbors, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree model\n",
    "tree = DecisionTreeClassifier(random_state = 0) #maximum depth of 5 leaves\n",
    "kbest = SelectKBest(f_classif) #select best 'k' features\n",
    "impute = Imputer(missing_values = 'NaN', strategy = 'median', axis = 0) #impute missing values: replacing NaNs with Median Column value for each column\n",
    "\n",
    "#Pipeline for Logistic Regression with L2 'Ridge' Regularization\n",
    "pipe_tree = Pipeline([('imputer', impute),\n",
    "                       ('kbest', kbest),\n",
    "                      ('dec_tree', tree)])\n",
    "#parameters for grid search cross validation \n",
    "parameters = {'kbest__k': [5, 10, 20, 40, 60], #building models with 40, 60, 80, and 100 most significant variables\n",
    "                 'dec_tree__max_depth' : [2,3,4,5]} #tuning tree depth for performance vs understanding\n",
    "\n",
    "#grid search\n",
    "grid_tree = GridSearchCV(pipe_tree, parameters, cv = 5, scoring = 'roc_auc') #run grid on parameters, 5-fold cross validation, AUC is evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [86] are constant.\n",
      "  UserWarning)\n",
      "C:\\tooling\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)), ('kbest', SelectKBest(k=10, score_func=<function f_classif at 0x000001D758DF30D0>)), ('dec_tree', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=N...         min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best'))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'kbest__k': [5, 10, 20, 40, 60], 'dec_tree__max_depth': [2, 3, 4, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#fit models\n",
    "grid_tree.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "Pipeline(memory=None,\n",
      "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)), ('kbest', SelectKBest(k=60, score_func=<function f_classif at 0x000001D758DF30D0>)), ('dec_tree', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None...         min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
      "            splitter='best'))])\n",
      "Decision Tree step:\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
      "            splitter='best')\n",
      "Best Parameters: {'dec_tree__max_depth': 5, 'kbest__k': 60}\n",
      "Best cross validation score: 0.80\n"
     ]
    }
   ],
   "source": [
    "print(\"Best estimator:\\n{}\".format(grid_tree.best_estimator_)) #prints best model and pipeline\n",
    "print(\"Decision Tree step:\\n{}\".format(grid_tree.best_estimator_.named_steps[\"dec_tree\"])) #prints logistic regression step of pipeline\n",
    "#print(\"Logistic Regression coefficients:\\n{}\".format(grid_tree.best_estimator_.named_steps[\"dec_tree\"].coef_)) #prints coefficients of best estimator\n",
    "print(\"Best Parameters: {}\".format(grid_tree.best_params_)) #outputs best parameters settings\n",
    "print(\"Best cross validation score: {:.2f}\".format(grid_tree.best_score_)) #best produced cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
